"""
Opus Access Public API Module - Packet-Based Implementation
===========================================================

KEY IMPROVEMENTS:
- Packet-based storage instead of OGG container
- opuslib for direct decoding (no ffmpeg for extraction)
- Sample-accurate random access
- Eliminates ffmpeg startup overhead for small segments

Essential Functions for aimport.py compatibility:
- import_opus_to_zarr()
- extract_audio_segment_opus() 
- parallel_extract_audio_segments_opus()
"""

import zarr
import numpy as np
import tempfile
import os
import pathlib
import subprocess
import time
import struct
from typing import List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor

# Import backend module - LAZY IMPORT to avoid circular imports
opus_index = None
from .utils import file_size
from .config import Config

# import and initialize logging
from .logsetup import get_module_logger
logger = get_module_logger(__file__)

# Try to import opuslib for direct decoding
try:
    import opuslib
    OPUSLIB_AVAILABLE = True
    logger.trace("opuslib available for direct Opus decoding")
except ImportError:
    OPUSLIB_AVAILABLE = False
    logger.warning("opuslib not available - falling back to ffmpeg for extraction")

# Constants
AUDIO_DATA_BLOB_ARRAY_NAME = "audio_data_blob_array"  # Legacy OGG container
OPUS_PACKETS_BLOB_ARRAY_NAME = "opus_packets_blob"   # NEW: Raw packets
OPUS_PACKET_INDEX_ARRAY_NAME = "opus_packet_index"   # NEW: Packet index
OPUS_HEADER_ARRAY_NAME = "opus_header"               # NEW: OpusHead

# OGG/Opus constants for parsing
OGG_PAGE_HEADER_SIZE = 27
OGG_SYNC_PATTERN = b'OggS'
OPUS_HEAD_MAGIC = b'OpusHead'
OPUS_TAGS_MAGIC = b'OpusTags'


class OpusPacketExtractor:
    """Extract raw Opus packets from OGG container"""
    
    def __init__(self, ogg_data: bytes):
        self.ogg_data = ogg_data
        self.pos = 0
        self.packets = []
        self.opus_header = None
        self.total_samples = 0
        
    def extract_all_packets(self) -> Tuple[List[bytes], bytes, int]:
        """
        Extract all Opus packets from OGG container
        
        Returns:
            Tuple of (packets_list, opus_header, total_samples)
        """
        logger.trace("Extracting Opus packets from OGG container...")
        
        while self.pos < len(self.ogg_data) - OGG_PAGE_HEADER_SIZE:
            if self._find_next_page():
                self._process_page()
        
        logger.trace(f"Extracted {len(self.packets)} Opus packets, total samples: {self.total_samples}")
        return self.packets, self.opus_header, self.total_samples
    
    def _find_next_page(self) -> bool:
        """Find next OGG page"""
        while self.pos < len(self.ogg_data) - 4:
            if self.ogg_data[self.pos:self.pos+4] == OGG_SYNC_PATTERN:
                return True
            self.pos += 1
        return False
    
    def _process_page(self):
        """Process a single OGG page and extract packets"""
        if self.pos + OGG_PAGE_HEADER_SIZE > len(self.ogg_data):
            return
        
        # Parse OGG page header
        header = struct.unpack('<4sBBQIIIB', self.ogg_data[self.pos:self.pos + OGG_PAGE_HEADER_SIZE])
        granule_position = header[3]
        segment_count = header[7]
        
        # Read segment table
        seg_table_start = self.pos + OGG_PAGE_HEADER_SIZE
        if seg_table_start + segment_count > len(self.ogg_data):
            return
        
        segment_table = self.ogg_data[seg_table_start:seg_table_start + segment_count]
        
        # Process segments (Opus packets)
        packet_start = seg_table_start + segment_count
        for segment_size in segment_table:
            if packet_start + segment_size > len(self.ogg_data):
                break
            
            packet_data = self.ogg_data[packet_start:packet_start + segment_size]
            self._process_packet(packet_data, granule_position)
            packet_start += segment_size
        
        # Update position to next page
        total_page_size = OGG_PAGE_HEADER_SIZE + segment_count + sum(segment_table)
        self.pos += total_page_size
    
    def _process_packet(self, packet_data: bytes, granule_position: int):
        """Process individual packet"""
        if not packet_data:
            return
        
        # Check if this is OpusHead header
        if packet_data.startswith(OPUS_HEAD_MAGIC):
            self.opus_header = packet_data
            logger.trace("Found OpusHead header packet")
            return
        
        # Skip OpusTags
        if packet_data.startswith(OPUS_TAGS_MAGIC):
            logger.trace("Skipping OpusTags packet")
            return
        
        # Regular Opus audio packet
        self.packets.append(packet_data)
        
        # Update total samples from granule position
        if granule_position != 0xFFFFFFFFFFFFFFFF:
            self.total_samples = granule_position


def _extract_opus_packets_from_ogg(ogg_data: bytes) -> Tuple[List[bytes], bytes, int]:
    """Extract Opus packets from OGG container"""
    extractor = OpusPacketExtractor(ogg_data)
    return extractor.extract_all_packets()


def _create_packet_based_zarr_structure(zarr_group: zarr.Group, packets: List[bytes], 
                                       opus_header: bytes, source_params: dict,
                                       first_sample_time_stamp, opus_bitrate: int) -> zarr.Array:
    """
    Create packet-based Zarr structure for efficient random access
    
    Args:
        zarr_group: Zarr group to store data
        packets: List of raw Opus packets
        opus_header: OpusHead header packet
        source_params: Source audio parameters
        first_sample_time_stamp: First sample timestamp
        opus_bitrate: Opus bitrate
        
    Returns:
        Packet index array for compatibility
    """
    logger.trace("Creating packet-based Zarr structure...")
    
    # 1. Store raw packets as concatenated blob
    total_packet_size = sum(len(packet) for packet in packets)
    packet_blob = zarr_group.create_array(
        name=OPUS_PACKETS_BLOB_ARRAY_NAME,
        compressor=None,
        shape=(total_packet_size,),
        chunks=(Config.original_audio_chunk_size,),
        shards=(Config.original_audio_chunks_per_shard * Config.original_audio_chunk_size,),
        dtype=np.uint8,
        overwrite=True,
    )
    
    # 2. Create packet index: [offset, size, samples_per_packet, cumulative_samples]
    packet_index_data = []
    offset = 0
    cumulative_samples = 0
    
    for packet in packets:
        packet_size = len(packet)
        
        # Estimate samples per packet (typical Opus frame: 960 samples at 48kHz)
        # TODO: Could parse packet header for exact sample count
        samples_per_packet = 960  # Standard 20ms frame at 48kHz
        
        packet_index_data.append([offset, packet_size, samples_per_packet, cumulative_samples])
        
        offset += packet_size
        cumulative_samples += samples_per_packet
    
    packet_index = zarr_group.create_array(
        name=OPUS_PACKET_INDEX_ARRAY_NAME,
        shape=(len(packets), 4),
        chunks=(min(1000, len(packets)), 4),
        dtype=np.uint64,
        overwrite=True,
    )
    
    # 3. Store OpusHead header
    if opus_header:
        header_array = zarr_group.create_array(
            name=OPUS_HEADER_ARRAY_NAME,
            shape=(len(opus_header),),
            chunks=(len(opus_header),),
            dtype=np.uint8,
            overwrite=True,
        )
        header_array[:] = np.frombuffer(opus_header, dtype=np.uint8)
        logger.trace("Stored OpusHead header for decoder initialization")
    
    # 4. Write packet data
    logger.trace("Writing packet data to Zarr arrays...")
    
    # Write concatenated packets
    offset = 0
    for packet in packets:
        packet_array = np.frombuffer(packet, dtype=np.uint8)
        packet_blob[offset:offset + len(packet_array)] = packet_array
        offset += len(packet_array)
    
    # Write packet index
    packet_index[:] = np.array(packet_index_data, dtype=np.uint64)
    
    # 5. Set metadata
    source_sample_rate = source_params.get("sampling_rate", 48000)
    source_channels = source_params.get("nb_channels", 1)
    is_ultrasonic = source_sample_rate > 48000
    sampling_rescale_factor = source_sample_rate / 48000.0 if is_ultrasonic else 1.0
    target_sample_rate = 48000 if is_ultrasonic else source_sample_rate
    
    attrs = {
        "codec": "opus",
        "nb_channels": source_channels,
        "sample_rate": target_sample_rate,
        "sampling_rescale_factor": sampling_rescale_factor,
        "container_type": "packet_based",  # NEW: Not OGG anymore
        "first_sample_time_stamp": first_sample_time_stamp,
        "opus_bitrate": opus_bitrate,
        "is_ultrasonic": is_ultrasonic,
        "original_sample_rate": source_sample_rate,
        "total_packets": len(packets),
        "packet_based_format": True,  # NEW: Flag for packet-based format
        "estimated_total_samples": cumulative_samples
    }
    
    # Apply metadata to all arrays
    packet_blob.attrs.update(attrs)
    packet_index.attrs.update(attrs)
    
    logger.trace(f"Created packet-based structure: {len(packets)} packets, {total_packet_size} bytes")
    return packet_index


def _create_temporary_ogg_file(audio_bytes: bytes) -> str:
    """Create temporary OGG file for ffmpeg access (legacy support)"""
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".ogg")
    temp_file.write(audio_bytes)
    temp_file.close()
    return temp_file.name


def _get_packet_data(zarr_group: zarr.Group, packet_idx: int) -> bytes:
    """Get raw packet data by index"""
    packet_index = zarr_group[OPUS_PACKET_INDEX_ARRAY_NAME]
    packet_blob = zarr_group[OPUS_PACKETS_BLOB_ARRAY_NAME]
    
    offset, size, _, _ = packet_index[packet_idx]
    return bytes(packet_blob[offset:offset + size])


def _find_packets_for_sample_range(zarr_group: zarr.Group, start_sample: int, end_sample: int) -> Tuple[int, int]:
    """Find packet range that covers the requested sample range"""
    packet_index = zarr_group[OPUS_PACKET_INDEX_ARRAY_NAME]
    cumulative_samples = packet_index[:, 3]  # Column 3: cumulative samples
    
    # Find start packet
    start_packet_idx = np.searchsorted(cumulative_samples, start_sample, side='right') - 1
    start_packet_idx = max(0, start_packet_idx)
    
    # Find end packet
    end_packet_idx = np.searchsorted(cumulative_samples, end_sample, side='right')
    end_packet_idx = min(end_packet_idx, packet_index.shape[0] - 1)
    
    return int(start_packet_idx), int(end_packet_idx)


def extract_audio_segment_opus(zarr_group: zarr.Group, audio_blob_array: zarr.Array, 
                              start_sample: int, end_sample: int, dtype=np.int16) -> np.ndarray:
    """
    Extract single audio segment using packet-based access or ffmpeg fallback
    
    Args:
        zarr_group: Zarr group with audio data
        audio_blob_array: Audio blob array (for legacy compatibility)
        start_sample: First sample to extract
        end_sample: Last sample to extract
        dtype: Output data type
        
    Returns:
        Extracted audio segment as numpy array
    """
    # Check if packet-based format is available
    if (OPUS_PACKET_INDEX_ARRAY_NAME in zarr_group and 
        OPUS_PACKETS_BLOB_ARRAY_NAME in zarr_group and 
        OPUSLIB_AVAILABLE):
        
        return _extract_segment_packet_based(zarr_group, start_sample, end_sample, dtype)
    else:
        # Fallback to legacy OGG container method
        logger.trace("Using legacy OGG container extraction")
        return _extract_segment_legacy(zarr_group, audio_blob_array, start_sample, end_sample, dtype)


def _extract_segment_packet_based(zarr_group: zarr.Group, start_sample: int, end_sample: int, dtype=np.int16) -> np.ndarray:
    """Extract segment using packet-based structure with opuslib"""
    try:
        # Get audio parameters
        packet_index = zarr_group[OPUS_PACKET_INDEX_ARRAY_NAME]
        sample_rate = packet_index.attrs.get('sample_rate', 48000)
        channels = packet_index.attrs.get('nb_channels', 1)
        
        # Initialize Opus decoder
        decoder = opuslib.Decoder(sample_rate, channels)
        
        # Find relevant packets
        start_packet_idx, end_packet_idx = _find_packets_for_sample_range(zarr_group, start_sample, end_sample)
        
        logger.trace(f"Extracting samples {start_sample}-{end_sample} using packets {start_packet_idx}-{end_packet_idx}")
        
        # Decode relevant packets
        pcm_data = []
        current_sample = 0
        
        for packet_idx in range(start_packet_idx, end_packet_idx + 1):
            packet_data = _get_packet_data(zarr_group, packet_idx)
            
            # Decode packet
            frame_samples = decoder.decode(packet_data)
            
            # Convert to requested dtype
            if dtype == np.int16:
                if frame_samples.dtype != np.int16:
                    frame_samples = (frame_samples * 32767).astype(np.int16)
            elif dtype == np.float32:
                if frame_samples.dtype != np.float32:
                    frame_samples = frame_samples.astype(np.float32) / 32767.0
            
            pcm_data.append(frame_samples)
            current_sample += frame_samples.shape[0] // channels
        
        # Concatenate all frames
        if not pcm_data:
            return np.array([])
        
        full_audio = np.concatenate(pcm_data, axis=0)
        
        # Trim to exact sample range
        samples_per_channel = full_audio.shape[0] // channels if channels > 1 else full_audio.shape[0]
        start_offset = max(0, start_sample - (start_packet_idx * 960))  # Approximate packet start
        end_offset = min(samples_per_channel, start_offset + (end_sample - start_sample + 1))
        
        if channels > 1:
            trimmed = full_audio[start_offset * channels:end_offset * channels]
            return trimmed.reshape(-1, channels)
        else:
            return full_audio[start_offset:end_offset]
            
    except Exception as e:
        logger.error(f"Error in packet-based extraction: {e}")
        return np.array([])


def _extract_segment_legacy(zarr_group: zarr.Group, audio_blob_array: zarr.Array,
                           start_sample: int, end_sample: int, dtype=np.int16) -> np.ndarray:
    """Legacy extraction using OGG container and ffmpeg"""
    try:
        # Load index from Zarr group
        if 'opus_index' not in zarr_group:
            raise ValueError("Opus index not found. Must be created first with build_opus_index().")
        
        opus_index_array = zarr_group['opus_index']
        
        # Get audio parameters
        sample_rate = audio_blob_array.attrs.get('sample_rate', 48000)
        channels = audio_blob_array.attrs.get('nb_channels', 1)
        
        # Find page range for sample range
        opus_backend = _get_opus_index_backend()
        start_idx, end_idx = opus_backend._find_page_range_for_samples(
            opus_index_array, start_sample, end_sample
        )
        
        if start_idx > end_idx:
            raise ValueError(f"Invalid sample range: start={start_sample}, end={end_sample}")
        
        # Load complete OGG data and create temporary file for ffmpeg
        complete_ogg_data = bytes(audio_blob_array[()])
        temp_file_path = _create_temporary_ogg_file(complete_ogg_data)
        
        try:
            # Calculate time positions for ffmpeg seeking
            sample_positions = opus_index_array[:, 2]  # OPUS_INDEX_COL_SAMPLE_POS from backend
            actual_start_sample = int(sample_positions[start_idx])
            
            # Convert sample positions to time for ffmpeg
            start_time_seconds = actual_start_sample / sample_rate
            duration_samples = end_sample - start_sample + 1
            duration_seconds = duration_samples / sample_rate
            
            # Decode with ffmpeg
            ffmpeg_cmd = [
                "ffmpeg",
                "-hide_banner", "-loglevel", "error",
                "-ss", str(start_time_seconds),
                "-t", str(duration_seconds),
                "-i", temp_file_path,
                "-ac", str(channels),
                "-ar", str(sample_rate),
                "-f", "s16le" if dtype == np.int16 else "f32le",
                "pipe:1"
            ]
            
            proc = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            pcm_bytes, stderr_output = proc.communicate()
            
            if proc.returncode != 0 or not pcm_bytes:
                error_msg = stderr_output.decode('utf-8', errors='ignore') if stderr_output else "Unknown error"
                raise RuntimeError(f"FFmpeg decoding failed: {error_msg}")
            
            # Convert PCM bytes to numpy array
            samples = np.frombuffer(pcm_bytes, dtype=dtype)
            if samples.size % channels != 0:
                samples = samples[:samples.size - (samples.size % channels)]
            
            if channels > 1:
                samples = samples.reshape(-1, channels)
            
            return samples
                
        finally:
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except Exception as e:
        logger.error(f"Error extracting Opus segment [{start_sample}:{end_sample}]: {e}")
        return np.array([])


def parallel_extract_audio_segments_opus(zarr_group: zarr.Group, audio_blob_array: zarr.Array, 
                                        segments: List[Tuple[int, int]], dtype=np.int16, 
                                        max_workers: int = 4) -> List[np.ndarray]:
    """Parallel extraction using packet-based access or ffmpeg fallback"""
    
    # AUTO-DETECT FORMAT
    has_packet_format = (
        OPUS_PACKET_INDEX_ARRAY_NAME in zarr_group and 
        OPUS_PACKETS_BLOB_ARRAY_NAME in zarr_group
    )
    
    has_legacy_format = (
        audio_blob_array is not None and 
        'opus_index' in zarr_group
    )
    
    if has_packet_format:
        logger.trace(f"Using packet-based parallel extraction for {len(segments)} segments")
        # Use packet-based extraction for all segments
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_segment = {
                executor.submit(
                    extract_audio_segment_opus, 
                    zarr_group, audio_blob_array, start, end, dtype
                ): (start, end) 
                for start, end in segments
            }
            
            results = {}
            for future in future_to_segment:
                segment = future_to_segment[future]
                try:
                    results[segment] = future.result()
                except Exception as e:
                    logger.error(f"Error in packet-based parallel extraction of segment {segment}: {e}")
                    results[segment] = np.array([])
            
            # Return results in original order
            return [results[segment] for segment in segments]
    
    elif has_legacy_format:
        logger.trace(f"Using legacy parallel extraction for {len(segments)} segments")
        # Use legacy method
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_segment = {
                executor.submit(
                    _extract_segment_legacy, 
                    zarr_group, audio_blob_array, start, end, dtype
                ): (start, end) 
                for start, end in segments
            }
            
            results = {}
            for future in future_to_segment:
                segment = future_to_segment[future]
                try:
                    results[segment] = future.result()
                except Exception as e:
                    logger.error(f"Error in legacy parallel extraction of segment {segment}: {e}")
                    results[segment] = np.array([])
            
            # Return results in original order
            return [results[segment] for segment in segments]
    
    else:
        raise ValueError("No supported Opus format found for parallel extraction")


def import_opus_to_zarr(zarr_group: zarr.Group, 
                       audio_file: str | pathlib.Path,
                       source_params: dict,
                       first_sample_time_stamp,
                       opus_bitrate: int = 160000,
                       temp_dir: str = "/tmp") -> zarr.Array:
    """
    Import audio file to packet-based Opus format in Zarr with automatic index creation
    
    NEW IMPLEMENTATION:
    1. ffmpeg â†’ temporary OGG file (supports all input formats)
    2. Extract raw Opus packets from OGG container  
    3. Store in packet-based Zarr structure
    4. Enables opuslib direct access without ffmpeg overhead
    
    Args:
        zarr_group: Zarr group for storage
        audio_file: Input audio file path
        source_params: Source audio parameters
        first_sample_time_stamp: First sample timestamp
        opus_bitrate: Opus encoding bitrate
        temp_dir: Temporary directory
        
    Returns:
        Packet index array (for compatibility)
    """
    logger.trace(f"import_opus_to_zarr() requested for file '{audio_file}' with packet-based implementation")
    
    audio_file = pathlib.Path(audio_file)
    
    # Extract source parameters
    source_sample_rate = source_params.get("sampling_rate", 48000)
    source_channels = source_params.get("nb_channels", 1)
    is_opus_source = source_params.get("is_opus", False)
    
    # Ultrasonic detection and handling
    is_ultrasonic = source_sample_rate > 48000
    sampling_rescale_factor = 1.0
    target_sample_rate = source_sample_rate
    
    if is_ultrasonic:
        sampling_rescale_factor = source_sample_rate / 48000.0
        target_sample_rate = 48000
        logger.trace(f"Ultrasonic source detected: {source_sample_rate}Hz -> 48kHz (factor: {sampling_rescale_factor:.3f})")
    
    # Create temporary OGG file using ffmpeg
    with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg', dir=temp_dir) as tmp_out:
        tmp_file = pathlib.Path(tmp_out.name)
    
    try:
        logger.trace("Step 1: Convert to OGG using ffmpeg...")
        
        # Prepare ffmpeg command for Opus conversion
        if is_opus_source and not is_ultrasonic:
            # 1:1 Opus data copy to avoid recompression loss
            ffmpeg_cmd = ["ffmpeg", "-y", "-i", str(audio_file), "-c:a", "copy", "-f", "ogg", str(tmp_file)]
        else:
            # Standard ffmpeg encoding
            ffmpeg_cmd = ["ffmpeg", "-y"]
            if is_ultrasonic:
                ffmpeg_cmd += ["-ar", "48000"]
            ffmpeg_cmd += ["-i", str(audio_file), "-c:a", "libopus", "-b:a", str(int(opus_bitrate)), 
                          "-vbr", "off", "-apply_phase_inv", "false", "-f", "ogg", str(tmp_file)]
        
        # Execute ffmpeg conversion
        subprocess.run(ffmpeg_cmd, check=True)
        logger.trace("Step 1 completed: OGG file created")
        
        # Read OGG data
        with open(tmp_file, "rb") as f:
            ogg_data = f.read()
        
        logger.trace("Step 2: Extract Opus packets from OGG container...")
        
        # Extract raw Opus packets from OGG container
        packets, opus_header, total_samples = _extract_opus_packets_from_ogg(ogg_data)
        
        if not packets:
            raise ValueError("No Opus packets found in OGG container")
        
        if not opus_header:
            raise ValueError("No OpusHead header found - invalid Opus stream")
        
        logger.trace(f"Step 2 completed: {len(packets)} packets extracted")
        
        logger.trace("Step 3: Create packet-based Zarr structure...")
        
        # Create packet-based Zarr structure
        packet_index = _create_packet_based_zarr_structure(
            zarr_group, packets, opus_header, source_params, 
            first_sample_time_stamp, opus_bitrate
        )
        
        logger.trace("Step 3 completed: Packet-based structure created")
        
        # Create legacy OGG blob for backward compatibility (optional)
        if Config.keep_legacy_ogg_blob:
            logger.trace("Creating legacy OGG blob for backward compatibility...")
            size = len(ogg_data)
            audio_blob_array = zarr_group.create_array(
                name=AUDIO_DATA_BLOB_ARRAY_NAME,
                compressor=None,
                shape=(size,),
                chunks=(Config.original_audio_chunk_size,),
                shards=(Config.original_audio_chunks_per_shard * Config.original_audio_chunk_size,),
                dtype=np.uint8,
                overwrite=True,
            )
            
            # Copy OGG data
            audio_blob_array[:] = np.frombuffer(ogg_data, dtype=np.uint8)
            
            # Set legacy attributes
            legacy_attrs = {
                "codec": "opus",
                "nb_channels": source_channels,
                "sample_rate": target_sample_rate,
                "sampling_rescale_factor": sampling_rescale_factor,
                "container_type": "ogg",  # Legacy format
                "first_sample_time_stamp": first_sample_time_stamp,
                "opus_bitrate": opus_bitrate,
                "is_ultrasonic": is_ultrasonic,
                "original_sample_rate": source_sample_rate
            }
            audio_blob_array.attrs.update(legacy_attrs)
            
            # Create legacy index for backward compatibility
            logger.trace("Creating legacy index for backward compatibility...")
            opus_backend = _get_opus_index_backend()
            opus_backend.build_opus_index(zarr_group, audio_blob_array)
        
        logger.success(f"Packet-based Opus import completed successfully for '{audio_file.name}'")
        logger.success(f"Format: {len(packets)} packets, opuslib-ready, no ffmpeg needed for extraction")
        
        return packet_index
        
    finally:
        # Clean up temporary file
        if tmp_file.exists():
            tmp_file.unlink()


def parallel_extract_audio_segments_opus_optimized(
    zarr_group: zarr.Group, audio_blob_array: zarr.Array,
    segments: List[Tuple[int, int]], 
    dtype=np.int16, max_workers: int = 4,
    max_batch_duration_seconds: float = 30.0,
    max_segments_per_batch: int = 50) -> List[np.ndarray]:
    """
    Batch-optimized extraction using packet-based structure
    
    NEW: Uses packet-based access for maximum efficiency
    """
    if (OPUS_PACKET_INDEX_ARRAY_NAME in zarr_group and 
        OPUS_PACKETS_BLOB_ARRAY_NAME in zarr_group and 
        OPUSLIB_AVAILABLE):
        
        logger.trace(f"Using packet-based batch extraction for {len(segments)} segments")
        return parallel_extract_audio_segments_opus(zarr_group, audio_blob_array, segments, dtype, max_workers)
    else:
        logger.trace(f"Using legacy extraction for {len(segments)} segments")
        return parallel_extract_audio_segments_opus(zarr_group, audio_blob_array, segments, dtype, max_workers)


def _get_opus_index_backend():
    """Lazy import opus_index_backend to avoid circular imports"""
    global opus_index
    if opus_index is None:
        from . import opus_index_backend as backend
        opus_index = backend
    return opus_index


def build_opus_index(zarr_group: zarr.Group, audio_blob_array: zarr.Array) -> zarr.Array:
    """Create Opus index (convenience wrapper for legacy compatibility)"""
    opus_backend = _get_opus_index_backend()
    return opus_backend.build_opus_index(zarr_group, audio_blob_array)


# Configuration flag for backward compatibility
if not hasattr(Config, 'keep_legacy_ogg_blob'):
    Config.keep_legacy_ogg_blob = False  # Default: no legacy blob


logger.trace("Opus Access API module loaded (packet-based implementation with opuslib support).")